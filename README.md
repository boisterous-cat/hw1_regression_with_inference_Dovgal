# HW1_Alekseev

# Результаты
## Предварительная обработка и анализ данных
* Первый этап:
    Заметим, что столбцы mileage, engine, max_power, torque на самом деле числовые, однако для них необходимо заняться обработкой данных. Для первых трех все легко - удалее все после чисел (и кроме точки). Для последней пишем функцию и решаем проблему. 

* Второй этап:
    Заменяем пропуски медианами и удаляем дубликаты

* Третий этап:
    Визуализируем данные. Обращаем внимание на наличие (отсутствие) корреляций у признаков и их распределение.

## Построение наивной модели
* Модель только на вещественных признаках:
    Удаляем все категориальные признаки и строим модель линейной регрессии, оцениваем по R^2 и MSE. Получаем результат:
    * Оценка R2: 0.6039184994828042
    * Оценка MSE: 227678956857.40744
    Наиболее информативным оказался признак max_power.
    Теперь попробуем Lasso-регрессию:
    * Оценка R2: 0.6039170534970607
    * Оценка MSE: 227679788051.3038
    Регуляризация не занулила веса.
    Далее перебором по сетке (c 10-ю фолдами) подбираем оптимальные параметры для Lasso-регрессии
    Получаем: {'alpha': 22001}
    Оценка R2: 0.5732606952761612
    Оценка MSE: 245301938168.55826
    Некоторые веса занулились: mileage, engine, torque, seats
    Перебором по сетке (c 10-ю фолдами) подбираем оптимальные параметры для ElasticNet-регрессии
    Получим: {'alpha': 0.46, 'l1_ratio': 0.7100000000000001}
    Оценка R2: 0.5746971324660818
    Оценка MSE: 244476233053.41086
 * Добавляем категориальные фичи:
    Из df_train удаляем столбцы с целевой переменной и названием автомобиля.
    Кодируем категориалльные фичи и seats методом OneHot-кодирования.
    Перебираем параметр регуляризации alpha для гребневой (ridge) регрессии с помощью класса - {'alpha': 7.900000000000006}
    Оценка R2: 0.6486646983442269
    Оценка MSE: 201957563995.58517

## Feature Engineering
* Реализуем следующие функции:
    1. Сделаем год квадратичным
    2. Логарифмируем selling_price (он распределен логнормально)
    3. Сделаем seats категориальной переменной. Чтобы не переобучаться заменим редко встречающиеся на Rare
    4. Из Name возьмем первое слово - производителя - и сделаем категориальной переменной. Чтобы не переобучаться заменим редко встречающиеся на Rare
    5. Лошадиные силы / расход: max_power / (100 / mileage)
    6. Объем двигателя / лошадиные силы: engine / max_power
    7. Преобразование torque на два числовых столбца (уже готово ранее)
    
    Подберем параметры для Ridge: {'alpha': 0.0}
    Получим качество модели:
    Оценка R2: 0.8794418054793518
    Оценка MSE: 69300292826.68285
    
    Наибольшее улучшение показала замена редких показателей на Rare и далее OHE
    Далее строим "Бизнесовую" метрику и получаем оценку - 32.1%. 

## Реализация сервиса на FastAPI
* Реализуем следующее:
1. средствами pydantic описываем класс базового объекта
2. класс с коллецией объектов
3. метод post, который получает на вход один объект описанного класса
4. метод post, который получает на вход коллекцию объектов описанного класса

Получаем:
![Alt Text](https://recordit.co/6G3dd9887A.gif)
